{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the .skeleton files provided in the NTU-RGB-D dataset\n",
    "\n",
    "S : setup number \n",
    "C : camera id\n",
    "P : performer id\n",
    "R : replication number\n",
    "A : action label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import ffmpeg\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "from joints import *\n",
    "from utils import *\n",
    "from play_skeleton import *\n",
    "\n",
    "ntu_path = \"/media/gnocchi/Seagate Backup Plus Drive/NTU-RGB-D/\"\n",
    "\n",
    "rgb_folder = \"nturgb+d_rgb/\"\n",
    "skeleton_folder = \"nturgb+d_skeletons/\"\n",
    "\n",
    "sample_name = os.path.splitext(random.choice(os.listdir(ntu_path + skeleton_folder)))[0]\n",
    "print(sample_name)\n",
    "# sample_name = \"S016C003P008R002A059\"\n",
    "# sample_name = \"S001C001P001R001A001\"\n",
    "# sample_name = \"S002C003P007R001A060\"\n",
    "# sample_name = \"S001C003P003R001A060\"\n",
    "# sample_name = \"S001C003P008R002A027\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton numpy array\n",
    "\n",
    "read_xyz(...) returns a (3, max_frame, num_joint=25, 2) numpy array\n",
    "\n",
    "read_color_xy(...) returns (2, max_frame, num_joint=25, 2) numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton = read_xyz(ntu_path + skeleton_folder + sample_name + \".skeleton\") # shape (3, 103, 25, 2)\n",
    "\n",
    "print(\"===== 3D skeleton =====\")\n",
    "print(skeleton[:, 0, :, 0])\n",
    "print(skeleton.transpose(3, 2, 0, 1)[0].shape)\n",
    "\n",
    "print(\"\\r\\n===== 2D RGB skeleton =====\")\n",
    "skeleton_2d = read_color_xy(ntu_path + skeleton_folder + sample_name + \".skeleton\")\n",
    "print(skeleton_2d[:, 0, :, 0])\n",
    "\n",
    "has_2_subjects = np.any(skeleton_2d[:, :, :, 1])\n",
    "print(\"Number of subjects : \" + str(int(has_2_subjects) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animateJointCoordinates(skeleton.transpose(3, 2, 0, 1)[0], connexion_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video playback with hand tracking for 1 or 2 subjects\n",
    "\n",
    "Creates a video object of size (seq_len, 1080, 1920, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = ffmpeg.probe(ntu_path + rgb_folder + sample_name + '_rgb.avi')\n",
    "video_info = next(x for x in probe['streams'] if x['codec_type'] == 'video')\n",
    "width = int(video_info['width'])\n",
    "height = int(video_info['height'])\n",
    "num_frames = int(video_info['nb_frames'])\n",
    "print(num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, err = (ffmpeg\n",
    "           .input(ntu_path + rgb_folder + sample_name + '_rgb.avi')\n",
    "           .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
    "           .run(capture_stdout=True)\n",
    ")\n",
    "video = np.frombuffer(out, np.uint8).reshape([-1, height, width, 3])\n",
    "print(video.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "ax = f.gca()\n",
    "f.set_size_inches(10,10)\n",
    "\n",
    "image = plt.imshow(video[0], interpolation='None', animated = True)\n",
    "\n",
    "# skeleton_2d shape (2{xy}, max_frame, num_joint=25, 2)\n",
    "right_hand_s1 = Circle((skeleton_2d[0, 0, Joints.HANDRIGHT, 0], skeleton_2d[1, 0, Joints.HANDRIGHT, 0]),15, color=\"red\")\n",
    "left_hand_s1 = Circle((skeleton_2d[0, 0, Joints.HANDLEFT, 0], skeleton_2d[1, 0, Joints.HANDLEFT, 0]),15, color=\"red\")\n",
    "\n",
    "ax.add_patch(right_hand_s1)\n",
    "ax.add_patch(left_hand_s1)\n",
    "\n",
    "if has_2_subjects:\n",
    "    right_hand_s2 = Circle((skeleton_2d[0, 0, Joints.HANDRIGHT, 1], skeleton_2d[1, 0, Joints.HANDRIGHT, 1]),15)\n",
    "    left_hand_s2 = Circle((skeleton_2d[0, 0, Joints.HANDLEFT, 1], skeleton_2d[1, 0, Joints.HANDLEFT, 1]),15)\n",
    "    \n",
    "    ax.add_patch(right_hand_s2)\n",
    "    ax.add_patch(left_hand_s2)\n",
    "\n",
    "\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "def videoAnimation(frame_index):\n",
    "    image.set_data(video[frame_index])\n",
    "    [p.remove() for p in ax.patches]\n",
    "    right_hand_s1 = Circle((skeleton_2d[0, frame_index, Joints.HANDRIGHT, 0], skeleton_2d[1, frame_index, Joints.HANDRIGHT, 0]),15, color='red')\n",
    "    left_hand_s1 = Circle((skeleton_2d[0, frame_index, Joints.HANDLEFT, 0], skeleton_2d[1, frame_index, Joints.HANDLEFT, 0]),15, color='red')\n",
    "    \n",
    "    ax.add_patch(right_hand_s1)\n",
    "    ax.add_patch(left_hand_s1)\n",
    "    \n",
    "    if has_2_subjects:\n",
    "        right_hand_s2 = Circle((skeleton_2d[0, frame_index, Joints.HANDRIGHT, 1], skeleton_2d[1, frame_index, Joints.HANDRIGHT, 1]),15)\n",
    "        left_hand_s2 = Circle((skeleton_2d[0, frame_index, Joints.HANDLEFT, 1], skeleton_2d[1, frame_index, Joints.HANDLEFT, 1]),15)\n",
    "\n",
    "        ax.add_patch(right_hand_s2)\n",
    "        ax.add_patch(left_hand_s2)\n",
    "    \n",
    "    return image,\n",
    "\n",
    "ani = animation.FuncAnimation(f, videoAnimation, interval = 200, frames = num_frames, repeat = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop around the hands\n",
    "\n",
    "According to \"Pose-conditioned Spatio-Temporal Attention for Human Action Recognition\" https://arxiv.org/pdf/1703.10106.pdf, the crops are 50x50p around hands on NTU dataset. The same cropping dimensions are kept on latter paper STA-Hands by same author.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_crops = extract_hands(skeleton_2d, video, crop_size) # shape (n_frames, 4, crop_size, crop_size, 3)\n",
    "if hand_crops.shape[1] == 2:\n",
    "    pad = np.zeros(hand_crops.shape, dtype=hand_crops.dtype)\n",
    "    hand_crops = np.concatenate((hand_crops, pad), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using video for variable from above of shape (seq_len, 1080, 1920, 3)\n",
    "f, (axs) = plt.subplots(2, 2)\n",
    "f.set_size_inches(8, 8)\n",
    "axs[0, 0].axis('off')\n",
    "axs[0, 1].axis('off')\n",
    "axs[1, 0].axis('off')\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "s1_l = axs[0, 0].imshow(hand_crops[0, 0])\n",
    "s1_r = axs[0, 1].imshow(hand_crops[0, 1])\n",
    "s2_l = axs[1, 0].imshow(hand_crops[0, 2])\n",
    "s2_r = axs[1, 1].imshow(hand_crops[0, 3])\n",
    "\n",
    "\n",
    "def videoAnimation(frame_index):\n",
    "    s1_l.set_data(hand_crops[frame_index, 0])\n",
    "    s1_r.set_data(hand_crops[frame_index, 1])\n",
    "    s2_l.set_data(hand_crops[frame_index, 2])\n",
    "    s2_r.set_data(hand_crops[frame_index, 3])\n",
    "    \n",
    "    axs[0, 0].set_title(frame_index)\n",
    "    axs[0, 1].set_title(frame_index)\n",
    "    axs[1, 0].set_title(frame_index)\n",
    "    axs[1, 1].set_title(frame_index)\n",
    "    \n",
    "    \n",
    "    return s1_l\n",
    "\n",
    "ani = animation.FuncAnimation(f, videoAnimation, interval = 200, frames = num_frames, repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
