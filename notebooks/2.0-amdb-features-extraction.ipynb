{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Trying out 2 ways of dealing with data:\n",
    "- Option 1 : save croped images and skeleton into pickle files\n",
    "- Option 2 : save croped images and skeleton into a unique h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path \n",
    "ntu_path = \"/home/gnocchi/Documents/datasets/NTU-RGB-D_toy/\"\n",
    "rgb_folder = \"nturgb+d_rgb/\"\n",
    "skeleton_folder = \"nturgb+d_skeletons/\"\n",
    "\n",
    "# Hyper parameters\n",
    "crop_size = 50\n",
    "offset = int(crop_size / 2)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import skvideo.io\n",
    "import skvideo.datasets\n",
    "\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "# Custom imports\n",
    "from utils import * \n",
    "from joints import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S001C001P001R001A039\n",
      "S001C001P001R001A052\n",
      "S001C001P001R001A031\n",
      "S001C001P001R001A023\n",
      "S001C001P001R001A017\n",
      "S001C001P001R001A056\n",
      "S001C001P001R001A043\n",
      "S001C001P001R001A007\n",
      "S001C001P001R001A009\n",
      "S001C001P001R001A057\n",
      "S001C001P001R001A015\n",
      "S001C001P001R001A029\n",
      "S001C001P001R001A014\n",
      "S001C001P001R001A002\n",
      "S001C001P001R001A020\n",
      "S001C001P001R001A006\n",
      "S001C001P001R001A047\n",
      "S001C001P001R001A046\n",
      "S001C001P001R001A038\n",
      "S001C001P001R001A011\n",
      "S001C001P001R001A058\n",
      "S001C001P001R001A025\n",
      "S001C001P001R001A001\n",
      "S001C001P001R001A040\n",
      "S001C001P001R001A051\n",
      "S001C001P001R001A045\n",
      "S001C001P001R001A016\n",
      "S001C001P001R001A048\n",
      "S001C001P001R001A030\n",
      "S001C001P001R001A042\n",
      "S001C001P001R001A024\n",
      "S001C001P001R001A019\n",
      "S001C001P001R001A010\n",
      "S001C001P001R001A059\n",
      "S001C001P001R001A012\n",
      "S001C001P001R001A005\n",
      "S001C001P001R001A033\n",
      "S001C001P001R001A026\n",
      "S001C001P001R001A053\n",
      "S001C001P001R001A034\n",
      "S001C001P001R001A041\n",
      "S001C001P001R001A035\n",
      "S001C001P001R001A055\n",
      "S001C001P001R001A022\n",
      "S001C001P001R001A054\n",
      "S001C001P001R001A003\n",
      "S001C001P001R001A060\n",
      "S001C001P001R001A036\n",
      "S001C001P001R001A028\n",
      "S001C001P001R001A032\n",
      "S001C001P001R001A044\n",
      "S001C001P001R001A008\n",
      "S001C001P001R001A018\n",
      "S001C001P001R001A021\n",
      "S001C001P001R001A004\n",
      "S001C001P001R001A049\n",
      "S001C001P001R001A037\n",
      "S001C001P001R001A050\n",
      "S001C001P001R001A027\n",
      "S001C001P001R001A013\n",
      "It took : 96.75892066955566 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Loop through skeleton files\n",
    "for filename in os.listdir(ntu_path + skeleton_folder):\n",
    "    # Retrieve skeleton data\n",
    "    skeleton = read_xyz(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "    skeleton_rgb = read_color_xy(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "    \n",
    "    # Assert skeletons are correct\n",
    "    assert skeleton.shape[1:] == skeleton_rgb.shape[1:]\n",
    "    \n",
    "    # Sequence code without extension\n",
    "    short_filename = os.path.splitext(filename)[0]\n",
    "    print(short_filename)\n",
    "        \n",
    "    # Read cooresponding video\n",
    "    videodata = skvideo.io.vread(ntu_path + rgb_folder + short_filename +'_rgb.avi') # shape (n_frames, 1080, 1920, 3)\n",
    "    \n",
    "    # Check that video data has same number of frames as skeleton\n",
    "    assert skeleton.shape[1] == videodata.shape[0]\n",
    "    \n",
    "    n_frames = videodata.shape[0]\n",
    "    \n",
    "    # Create empty np arrays containing crops of hands from videos\n",
    "    # shape (n_frames, number of hands (2 subjects), x, y)\n",
    "    hand_crops = np.zeros((n_frames, 4, crop_size, crop_size, 3), dtype=np.uint8)\n",
    "    \n",
    "    left_hand_s0_x = int(skeleton_rgb[1, 0, Joints.HANDLEFT, 0])\n",
    "    left_hand_s0_y = int(skeleton_rgb[0, 0, Joints.HANDLEFT, 0])\n",
    "    \n",
    "    right_hand_s0_x = int(skeleton_rgb[1, 0, Joints.HANDRIGHT, 0])\n",
    "    right_hand_s0_y = int(skeleton_rgb[0, 0, Joints.HANDRIGHT, 0])\n",
    "    \n",
    "    left_hand_s1_x = int(skeleton_rgb[1, 0, Joints.HANDLEFT, 1])\n",
    "    left_hand_s1_y = int(skeleton_rgb[0, 0, Joints.HANDLEFT, 1])\n",
    "    \n",
    "    right_hand_s1_x = int(skeleton_rgb[1, 0, Joints.HANDRIGHT, 1])\n",
    "    right_hand_s1_y = int(skeleton_rgb[0, 0, Joints.HANDRIGHT, 1])\n",
    "    \n",
    "    hand_crops[:, 0] = videodata[:, \n",
    "                                 left_hand_s0_x-offset:left_hand_s0_x+offset, \n",
    "                                 left_hand_s0_y-offset:left_hand_s0_y+offset, \n",
    "                                 :]\n",
    "    hand_crops[:, 1] = videodata[:, \n",
    "                                 right_hand_s0_x-offset:right_hand_s0_x+offset, \n",
    "                                 right_hand_s0_y-offset:right_hand_s0_y+offset, \n",
    "                                 :]\n",
    "    if right_hand_s1_x + right_hand_s1_y + left_hand_s1_x + left_hand_s1_y != 0:\n",
    "        hand_crops[:, 2] = videodata[:, \n",
    "                                     left_hand_s1_x-offset:left_hand_s1_x+offset, \n",
    "                                     left_hand_s1_y-offset:left_hand_s1_y+offset, \n",
    "                                     :]\n",
    "        hand_crops[:, 3] = videodata[:, \n",
    "                                     right_hand_s1_x-offset:right_hand_s1_x+offset, \n",
    "                                     right_hand_s1_y-offset:right_hand_s1_y+offset, \n",
    "                                     :]\n",
    "    with open('pickles/' + short_filename + '_skeleton.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(skeleton, pickle_file)\n",
    "        \n",
    "    with open('pickles/' + short_filename + '_rgb.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(hand_crops, pickle_file)\n",
    "        \n",
    "end = time.time()\n",
    "print(\"It took : \" + str(end - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h5py approach\n",
    "\n",
    "Takes same time and same space without compression. \n",
    "\n",
    "Takes longer (~15s per 60 samples) when compressing with GZIP, compression_opts=9 but saves ~115MB per 60 samples.\n",
    "\n",
    "Takes longer (4s per 60 samples) when compression with Lzf, but saves 90MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S001C001P001R001A039\n",
      "S001C001P001R001A052\n",
      "S001C001P001R001A031\n",
      "S001C001P001R001A023\n",
      "S001C001P001R001A017\n",
      "S001C001P001R001A056\n",
      "S001C001P001R001A043\n",
      "S001C001P001R001A007\n",
      "S001C001P001R001A009\n",
      "S001C001P001R001A057\n",
      "S001C001P001R001A015\n",
      "S001C001P001R001A029\n",
      "S001C001P001R001A014\n",
      "S001C001P001R001A002\n",
      "S001C001P001R001A020\n",
      "S001C001P001R001A006\n",
      "S001C001P001R001A047\n",
      "S001C001P001R001A046\n",
      "S001C001P001R001A038\n",
      "S001C001P001R001A011\n",
      "S001C001P001R001A058\n",
      "S001C001P001R001A025\n",
      "S001C001P001R001A001\n",
      "S001C001P001R001A040\n",
      "S001C001P001R001A051\n",
      "S001C001P001R001A045\n",
      "S001C001P001R001A016\n",
      "S001C001P001R001A048\n",
      "S001C001P001R001A030\n",
      "S001C001P001R001A042\n",
      "S001C001P001R001A024\n",
      "S001C001P001R001A019\n",
      "S001C001P001R001A010\n",
      "S001C001P001R001A059\n",
      "S001C001P001R001A012\n",
      "S001C001P001R001A005\n",
      "S001C001P001R001A033\n",
      "S001C001P001R001A026\n",
      "S001C001P001R001A053\n",
      "S001C001P001R001A034\n",
      "S001C001P001R001A041\n",
      "S001C001P001R001A035\n",
      "S001C001P001R001A055\n",
      "S001C001P001R001A022\n",
      "S001C001P001R001A054\n",
      "S001C001P001R001A003\n",
      "S001C001P001R001A060\n",
      "S001C001P001R001A036\n",
      "S001C001P001R001A028\n",
      "S001C001P001R001A032\n",
      "S001C001P001R001A044\n",
      "S001C001P001R001A008\n",
      "S001C001P001R001A018\n",
      "S001C001P001R001A021\n",
      "S001C001P001R001A004\n",
      "S001C001P001R001A049\n",
      "S001C001P001R001A037\n",
      "S001C001P001R001A050\n",
      "S001C001P001R001A027\n",
      "S001C001P001R001A013\n",
      "It took : 109.46575021743774 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with h5py.File('datasets.h5', 'w') as hdf:\n",
    "    # Loop through skeleton files\n",
    "    for filename in os.listdir(ntu_path + skeleton_folder):\n",
    "        # Retrieve skeleton data\n",
    "        skeleton = read_xyz(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "        skeleton_rgb = read_color_xy(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "\n",
    "        # Assert skeletons are correct\n",
    "        assert skeleton.shape[1:] == skeleton_rgb.shape[1:]\n",
    "\n",
    "        # Sequence code without extension\n",
    "        short_filename = os.path.splitext(filename)[0]\n",
    "        print(short_filename)\n",
    "\n",
    "        # Read cooresponding video\n",
    "        videodata = skvideo.io.vread(ntu_path + rgb_folder + short_filename +'_rgb.avi') # shape (n_frames, 1080, 1920, 3)\n",
    "\n",
    "        # Check that video data has same number of frames as skeleton\n",
    "        assert skeleton.shape[1] == videodata.shape[0]\n",
    "\n",
    "        n_frames = videodata.shape[0]\n",
    "\n",
    "        # Create empty np arrays containing crops of hands from videos\n",
    "        # shape (n_frames, number of hands (2 subjects), x, y)\n",
    "        hand_crops = np.zeros((n_frames, 4, crop_size, crop_size, 3), dtype=np.uint8)\n",
    "\n",
    "        left_hand_s0_x = int(skeleton_rgb[1, 0, Joints.HANDLEFT, 0])\n",
    "        left_hand_s0_y = int(skeleton_rgb[0, 0, Joints.HANDLEFT, 0])\n",
    "\n",
    "        right_hand_s0_x = int(skeleton_rgb[1, 0, Joints.HANDRIGHT, 0])\n",
    "        right_hand_s0_y = int(skeleton_rgb[0, 0, Joints.HANDRIGHT, 0])\n",
    "\n",
    "        left_hand_s1_x = int(skeleton_rgb[1, 0, Joints.HANDLEFT, 1])\n",
    "        left_hand_s1_y = int(skeleton_rgb[0, 0, Joints.HANDLEFT, 1])\n",
    "\n",
    "        right_hand_s1_x = int(skeleton_rgb[1, 0, Joints.HANDRIGHT, 1])\n",
    "        right_hand_s1_y = int(skeleton_rgb[0, 0, Joints.HANDRIGHT, 1])\n",
    "\n",
    "        hand_crops[:, 0] = videodata[:, \n",
    "                                     left_hand_s0_x-offset:left_hand_s0_x+offset, \n",
    "                                     left_hand_s0_y-offset:left_hand_s0_y+offset, \n",
    "                                     :]\n",
    "        hand_crops[:, 1] = videodata[:, \n",
    "                                     right_hand_s0_x-offset:right_hand_s0_x+offset, \n",
    "                                     right_hand_s0_y-offset:right_hand_s0_y+offset, \n",
    "                                     :]\n",
    "        if right_hand_s1_x + right_hand_s1_y + left_hand_s1_x + left_hand_s1_y != 0:\n",
    "            hand_crops[:, 2] = videodata[:, \n",
    "                                         left_hand_s1_x-offset:left_hand_s1_x+offset, \n",
    "                                         left_hand_s1_y-offset:left_hand_s1_y+offset, \n",
    "                                         :]\n",
    "            hand_crops[:, 3] = videodata[:, \n",
    "                                         right_hand_s1_x-offset:right_hand_s1_x+offset, \n",
    "                                         right_hand_s1_y-offset:right_hand_s1_y+offset, \n",
    "                                         :]\n",
    "            \n",
    "        sample = hdf.create_group(short_filename)\n",
    "        sample.create_dataset(\"skeleton\", data = skeleton, compression=\"gzip\", compression_opts=9)\n",
    "        sample.create_dataset(\"rgb\", data = hand_crops, compression=\"gzip\", compression_opts=9)\n",
    "        \n",
    "end = time.time()\n",
    "print(\"It took : \" + str(end - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
