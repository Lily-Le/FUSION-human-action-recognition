{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Trying out 2 ways of dealing with data:\n",
    "- Option 1 : save croped images and skeleton into pickle files\n",
    "- Option 2 : save croped images and skeleton into a unique h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path \n",
    "# ntu_path = \"/home/gnocchi/Documents/datasets/NTU-RGB-D_toy/\"\n",
    "ntu_path = \"/media/gnocchi/Seagate Backup Plus Drive/NTU-RGB-D/\"\n",
    "\n",
    "rgb_folder = \"nturgb+d_rgb/\"\n",
    "skeleton_folder = \"nturgb+d_skeletons/\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import skvideo.io\n",
    "import skvideo.datasets\n",
    "\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "# Custom imports\n",
    "from utils import * \n",
    "from joints import *\n",
    "\n",
    "# Remove previous log file\n",
    "os.remove(ntu_path + \"log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "start = time.time()\n",
    "\n",
    "# Loop through skeleton files\n",
    "for filename in os.listdir(ntu_path + skeleton_folder):\n",
    "    # Retrieve skeleton data\n",
    "    skeleton = read_xyz(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "    skeleton_rgb = read_color_xy(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "    \n",
    "    # Assert skeletons are correct\n",
    "    assert skeleton.shape[1:] == skeleton_rgb.shape[1:]\n",
    "    \n",
    "    # Sequence code without extension\n",
    "    short_filename = os.path.splitext(filename)[0]\n",
    "    print(short_filename)\n",
    "        \n",
    "    # Read cooresponding video\n",
    "    videodata = skvideo.io.vread(ntu_path + rgb_folder + short_filename +'_rgb.avi') # shape (n_frames, 1080, 1920, 3)\n",
    "    \n",
    "    # Check that video data has same number of frames as skeleton\n",
    "    assert skeleton.shape[1] == videodata.shape[0]\n",
    "    \n",
    "    n_frames = videodata.shape[0]\n",
    "    \n",
    "    # Create empty np arrays containing crops of hands from videos\n",
    "    # shape (n_frames, number of hands (2 subjects), x, y)\n",
    "    hand_crops = np.zeros((n_frames, 4, crop_size, crop_size, 3), dtype=np.uint8)\n",
    "    \n",
    "    left_hand_s0_x = int(skeleton_rgb[1, 0, Joints.HANDLEFT, 0])\n",
    "    left_hand_s0_y = int(skeleton_rgb[0, 0, Joints.HANDLEFT, 0])\n",
    "    \n",
    "    right_hand_s0_x = int(skeleton_rgb[1, 0, Joints.HANDRIGHT, 0])\n",
    "    right_hand_s0_y = int(skeleton_rgb[0, 0, Joints.HANDRIGHT, 0])\n",
    "    \n",
    "    left_hand_s1_x = int(skeleton_rgb[1, 0, Joints.HANDLEFT, 1])\n",
    "    left_hand_s1_y = int(skeleton_rgb[0, 0, Joints.HANDLEFT, 1])\n",
    "    \n",
    "    right_hand_s1_x = int(skeleton_rgb[1, 0, Joints.HANDRIGHT, 1])\n",
    "    right_hand_s1_y = int(skeleton_rgb[0, 0, Joints.HANDRIGHT, 1])\n",
    "    \n",
    "    hand_crops[:, 0] = videodata[:, \n",
    "                                 left_hand_s0_x-offset:left_hand_s0_x+offset, \n",
    "                                 left_hand_s0_y-offset:left_hand_s0_y+offset, \n",
    "                                 :]\n",
    "    hand_crops[:, 1] = videodata[:, \n",
    "                                 right_hand_s0_x-offset:right_hand_s0_x+offset, \n",
    "                                 right_hand_s0_y-offset:right_hand_s0_y+offset, \n",
    "                                 :]\n",
    "    if right_hand_s1_x + right_hand_s1_y + left_hand_s1_x + left_hand_s1_y != 0:\n",
    "        hand_crops[:, 2] = videodata[:, \n",
    "                                     left_hand_s1_x-offset:left_hand_s1_x+offset, \n",
    "                                     left_hand_s1_y-offset:left_hand_s1_y+offset, \n",
    "                                     :]\n",
    "        hand_crops[:, 3] = videodata[:, \n",
    "                                     right_hand_s1_x-offset:right_hand_s1_x+offset, \n",
    "                                     right_hand_s1_y-offset:right_hand_s1_y+offset, \n",
    "                                     :]\n",
    "    with open('pickles/' + short_filename + '_skeleton.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(skeleton, pickle_file)\n",
    "        \n",
    "    with open('pickles/' + short_filename + '_rgb.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(hand_crops, pickle_file)\n",
    "        \n",
    "end = time.time()\n",
    "print(\"It took : \" + str(end - start) + \" seconds\")\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h5py approach\n",
    "\n",
    "Takes same time and same space without compression. \n",
    "\n",
    "Takes longer (~15s per 60 samples) when compressing with GZIP, compression_opts=9 but saves ~115MB per 60 samples.\n",
    "\n",
    "Takes longer (4s per 60 samples) when compression with Lzf, but saves 90MB\n",
    "\n",
    "Notes :\n",
    "- S016C003P008R002A059 issue first skeleton too far left could not broadcast input array from shape (114,50,13,3) into shape (114,50,50,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "It took : 0.05136823654174805 seconds\n",
      "100\n",
      "It took : 303.7203357219696 seconds\n",
      "200\n",
      "It took : 700.6214907169342 seconds\n",
      "300\n",
      "It took : 1120.7732331752777 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7ab38c034364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Read cooresponding video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mvideodata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntu_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrgb_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshort_filename\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_rgb.avi'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape (n_frames, 1080, 1920, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Check that video data has same number of frames as skeleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ntu-rgb-d/lib/python3.5/site-packages/skvideo/io/io.py\u001b[0m in \u001b[0;36mvread\u001b[0;34m(fname, height, width, num_frames, as_grey, inputdict, outputdict, backend, verbosity)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mvideodata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mvideodata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ntu-rgb-d/lib/python3.5/site-packages/skvideo/io/abstract.py\u001b[0m in \u001b[0;36mnextFrame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputframenum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ntu-rgb-d/lib/python3.5/site-packages/skvideo/io/abstract.py\u001b[0m in \u001b[0;36m_readFrame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_readFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Read and convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_frame_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ntu-rgb-d/lib/python3.5/site-packages/skvideo/io/abstract.py\u001b[0m in \u001b[0;36m_read_frame_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;31m# Read framesize bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframesize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mframesize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "i = 0\n",
    "with h5py.File(ntu_path + 'datasets.h5', 'w') as hdf:\n",
    "    # Loop through skeleton files\n",
    "    for filename in os.listdir(ntu_path + skeleton_folder):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            end = time.time()\n",
    "            print(\"It took : \" + str(end - start) + \" seconds\")\n",
    "            \n",
    "        i += 1\n",
    "        # Retrieve skeleton data\n",
    "        skeleton = read_xyz(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "        skeleton_rgb = read_color_xy(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "\n",
    "        # Assert skeletons are correct\n",
    "        assert skeleton.shape[1:] == skeleton_rgb.shape[1:]\n",
    "\n",
    "        # Sequence code without extension\n",
    "        short_filename = os.path.splitext(filename)[0]\n",
    "        f = open(ntu_path + \"log.txt\",\"a+\")\n",
    "        f.write(short_filename)\n",
    "        f.write(\"\\r\\n\")\n",
    "        f.close()\n",
    "        # print(short_filename)\n",
    "\n",
    "        # Read cooresponding video\n",
    "        videodata = skvideo.io.vread(ntu_path + rgb_folder + short_filename +'_rgb.avi') # shape (n_frames, 1080, 1920, 3)\n",
    "\n",
    "        # Check that video data has same number of frames as skeleton\n",
    "        assert skeleton.shape[1] == videodata.shape[0]\n",
    "\n",
    "        n_frames = videodata.shape[0]\n",
    "\n",
    "        # Create empty np arrays containing crops of hands from videos\n",
    "        # shape (n_frames, number of hands (2 subjects), x, y)\n",
    "        hand_crops = extract_hands(skeleton_rgb, videodata, crop_size) # shape (n_frames, 4, crop_size, crop_size, 3)\n",
    "            \n",
    "        sample = hdf.create_group(short_filename)\n",
    "        sample.create_dataset(\"skeleton\", data = skeleton, compression=\"lzf\")# , compression_opts=9)\n",
    "        sample.create_dataset(\"rgb\", data = hand_crops, compression=\"lzf\") #, compression_opts=9)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
