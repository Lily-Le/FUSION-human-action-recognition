{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Trying out 2 ways of dealing with data:\n",
    "- Option 1 : save croped images and skeleton into pickle files\n",
    "- Option 2 : save croped images and skeleton into a unique h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path \n",
    "# ntu_path = \"/home/gnocchi/Documents/datasets/NTU-RGB-D_toy/\"\n",
    "ntu_path = \"/media/gnocchi/Seagate Backup Plus Drive/NTU-RGB-D/\"\n",
    "\n",
    "rgb_folder = \"nturgb+d_rgb/\"\n",
    "skeleton_folder = \"nturgb+d_skeletons/\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import skvideo.io\n",
    "import skvideo.datasets\n",
    "\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "# Custom imports\n",
    "from utils import * \n",
    "from joints import *\n",
    "\n",
    "# Remove previous log file\n",
    "os.remove(ntu_path + \"log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "start = time.time()\n",
    "\n",
    "# Loop through skeleton files\n",
    "for filename in os.listdir(ntu_path + skeleton_folder):\n",
    "    # Retrieve skeleton data\n",
    "    skeleton = read_xyz(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "    skeleton_rgb = read_color_xy(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "    \n",
    "    # Assert skeletons are correct\n",
    "    assert skeleton.shape[1:] == skeleton_rgb.shape[1:]\n",
    "    \n",
    "    # Sequence code without extension\n",
    "    short_filename = os.path.splitext(filename)[0]\n",
    "    print(short_filename)\n",
    "        \n",
    "    # Read cooresponding video\n",
    "    videodata = skvideo.io.vread(ntu_path + rgb_folder + short_filename +'_rgb.avi') # shape (n_frames, 1080, 1920, 3)\n",
    "    \n",
    "    # Check that video data has same number of frames as skeleton\n",
    "    assert skeleton.shape[1] == videodata.shape[0]\n",
    "    \n",
    "    n_frames = videodata.shape[0]\n",
    "    \n",
    "    # Create empty np arrays containing crops of hands from videos\n",
    "    # shape (n_frames, number of hands (2 subjects), x, y)\n",
    "    hand_crops = np.zeros((n_frames, 4, crop_size, crop_size, 3), dtype=np.uint8)\n",
    "    \n",
    "    left_hand_s0_x = int(skeleton_rgb[1, 0, Joints.HANDLEFT, 0])\n",
    "    left_hand_s0_y = int(skeleton_rgb[0, 0, Joints.HANDLEFT, 0])\n",
    "    \n",
    "    right_hand_s0_x = int(skeleton_rgb[1, 0, Joints.HANDRIGHT, 0])\n",
    "    right_hand_s0_y = int(skeleton_rgb[0, 0, Joints.HANDRIGHT, 0])\n",
    "    \n",
    "    left_hand_s1_x = int(skeleton_rgb[1, 0, Joints.HANDLEFT, 1])\n",
    "    left_hand_s1_y = int(skeleton_rgb[0, 0, Joints.HANDLEFT, 1])\n",
    "    \n",
    "    right_hand_s1_x = int(skeleton_rgb[1, 0, Joints.HANDRIGHT, 1])\n",
    "    right_hand_s1_y = int(skeleton_rgb[0, 0, Joints.HANDRIGHT, 1])\n",
    "    \n",
    "    hand_crops[:, 0] = videodata[:, \n",
    "                                 left_hand_s0_x-offset:left_hand_s0_x+offset, \n",
    "                                 left_hand_s0_y-offset:left_hand_s0_y+offset, \n",
    "                                 :]\n",
    "    hand_crops[:, 1] = videodata[:, \n",
    "                                 right_hand_s0_x-offset:right_hand_s0_x+offset, \n",
    "                                 right_hand_s0_y-offset:right_hand_s0_y+offset, \n",
    "                                 :]\n",
    "    if right_hand_s1_x + right_hand_s1_y + left_hand_s1_x + left_hand_s1_y != 0:\n",
    "        hand_crops[:, 2] = videodata[:, \n",
    "                                     left_hand_s1_x-offset:left_hand_s1_x+offset, \n",
    "                                     left_hand_s1_y-offset:left_hand_s1_y+offset, \n",
    "                                     :]\n",
    "        hand_crops[:, 3] = videodata[:, \n",
    "                                     right_hand_s1_x-offset:right_hand_s1_x+offset, \n",
    "                                     right_hand_s1_y-offset:right_hand_s1_y+offset, \n",
    "                                     :]\n",
    "    with open('pickles/' + short_filename + '_skeleton.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(skeleton, pickle_file)\n",
    "        \n",
    "    with open('pickles/' + short_filename + '_rgb.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(hand_crops, pickle_file)\n",
    "        \n",
    "end = time.time()\n",
    "print(\"It took : \" + str(end - start) + \" seconds\")\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h5py approach\n",
    "\n",
    "Takes same time and same space without compression. \n",
    "\n",
    "Takes longer (~15s per 60 samples) when compressing with GZIP, compression_opts=9 but saves ~115MB per 60 samples.\n",
    "\n",
    "Takes longer (4s per 60 samples) when compression with Lzf, but saves 90MB\n",
    "\n",
    "Notes :\n",
    "- S016C003P008R002A059 issue first skeleton too far left could not broadcast input array from shape (114,50,13,3) into shape (114,50,50,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "i = 0\n",
    "with h5py.File(ntu_path + 'datasets.h5', 'w') as hdf:\n",
    "    # Loop through skeleton files\n",
    "    for filename in os.listdir(ntu_path + skeleton_folder):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            end = time.time()\n",
    "            print(\"It took : \" + str(end - start) + \" seconds\")\n",
    "            \n",
    "        i += 1\n",
    "        # Retrieve skeleton data\n",
    "        skeleton = read_xyz(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "        skeleton_rgb = read_color_xy(ntu_path + skeleton_folder + filename) # shape (2, max_frame, num_joint=25, n_subjects)\n",
    "\n",
    "        # Assert skeletons are correct\n",
    "        assert skeleton.shape[1:] == skeleton_rgb.shape[1:]\n",
    "\n",
    "        # Sequence code without extension\n",
    "        short_filename = os.path.splitext(filename)[0]\n",
    "        f = open(ntu_path + \"log.txt\",\"a+\")\n",
    "        f.write(short_filename)\n",
    "        f.write(\"\\r\\n\")\n",
    "        f.close()\n",
    "        # print(short_filename)\n",
    "\n",
    "        # Read cooresponding video\n",
    "        videodata = skvideo.io.vread(ntu_path + rgb_folder + short_filename +'_rgb.avi') # shape (n_frames, 1080, 1920, 3)\n",
    "\n",
    "        # Check that video data has same number of frames as skeleton\n",
    "        assert skeleton.shape[1] == videodata.shape[0]\n",
    "\n",
    "        n_frames = videodata.shape[0]\n",
    "\n",
    "        # Create empty np arrays containing crops of hands from videos\n",
    "        # shape (n_frames, number of hands (2 subjects), x, y)\n",
    "        hand_crops = extract_hands(skeleton_rgb, videodata, crop_size) # shape (n_frames, 4, crop_size, crop_size, 3)\n",
    "            \n",
    "        sample = hdf.create_group(short_filename)\n",
    "        sample.create_dataset(\"skeleton\", data = skeleton, compression=\"lzf\")# , compression_opts=9)\n",
    "        sample.create_dataset(\"rgb\", data = hand_crops, compression=\"lzf\") #, compression_opts=9)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
